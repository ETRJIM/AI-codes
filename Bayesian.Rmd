```{r}
#Dataset
course_grade<- read.table("2020_bn_nb_data.txt",head=TRUE)
head(course_grade)
summary(course_grade)
```


```{r}
# Bayesian network and Conditional probability tables of dependent data
library(bnlearn)
course_grade<-lapply(course_grade,as.factor)
course_grade<-data.frame(course_grade)
course_grade.net<-hc(course_grade[,-9],score="k2")
plot(course_grade.net)
course_grade.net.fit<-bn.fit(course_grade.net, course_grade[,-9])
print(course_grade.net.fit)

```


```{r}
# Considering data to be independent 
library(bnclassify)
library(graph)
library(bnlearn)
course_grade<- read.table("2020_bn_nb_data.txt",head=TRUE)
course_grade<-lapply(course_grade,as.factor)
course_grade<-data.frame(course_grade)
nb.grades<-nb(class="QP",dataset=course_grade)
plot(nb.grades)
nb.grades <- lp(nb.grades, course_grade, smooth = 0)
a<- params(nb.grades)[['EC100']]
b<- params(nb.grades)[['EC160']]
c<- params(nb.grades)[['IT101']]
d<- params(nb.grades)[['IT161']]
e<- params(nb.grades)[['MA101']]
f<- params(nb.grades)[['PH100']]
g<- params(nb.grades)[['PH160']]
h<- params(nb.grades)[['HS101']]
cp<-params(nb.grades)[["QP"]]
print(a)
print(b)
print(c)
print(d)
print(e)
print(f)
print(g)
print(h)
print(cp)
```



```{r}
# taking 70% of the data as training and 30% as test
library(bnlearn)
library(e1071) 
library(caTools) 
library(caret)
i<- 0
while(i<20)
{
split <- sample.split(course_grade, SplitRatio = 0.7) 
train_cl <- subset(course_grade, split == "TRUE") 
test_cl <- subset(course_grade, split == "FALSE")
train_cl
test_cl
i=i+1
nb.train<-nb(class="QP",dataset=train_cl)
nb.train<-lp(nb.train,train_cl,smooth=0)

p<-predict(nb.train,test_cl)
print(p)
cm<-table(predicted=p, true=test_cl$QP)
print(cm)
accuarcy<-sum(cm * diag(1, nrow(cm), ncol(cm))) / sum(cm)
print(accuarcy)
}
```

```{r}
library(bnlearn)
library(e1071) 
library(caTools) 
library(caret)
i<- 0
while(i<20)
{
split <- sample.split(course_grade, SplitRatio = 0.7) 
train_cl <- subset(course_grade, split == "TRUE") 
test_cl <- subset(course_grade, split == "FALSE")
#print(train_cl)
#print(test_cl)
i=i+1
tn <- tan_cl('QP', train_cl)
tn <- lp(tn, train_cl, smooth = 1)
#plot(tn) see if you want
p <- predict(tn, test_cl)
print(p)
bnclassify::accuracy(p, test_cl$QP)
print(accuarcy)
}
```


```{r}
tn <- tan_cl('QP', course_grade)
tn <- lp(tn, course_grade, smooth = 1)
plot(tn)
p <- predict(tn, course_grade, prob = TRUE)
p
p <- predict(tn, course_grade)
bnclassify::accuracy(p, course_grade$QP)
```